import os
import time
import requests
from dotenv import load_dotenv

load_dotenv()

API_KEY = os.getenv("RUNPOD_API_KEY")
POD_ID = os.getenv("RUNPOD_POD_ID")
MISTRAL_API = f"https://{POD_ID}-8000.proxy.runpod.net/analyze"
GRAPHQL_URL = "https://api.runpod.io/graphql"
HEADERS = {"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"}

# 1Ô∏è‚É£ V√©rifie que le pod est bien configur√© avec GPU
def check_gpu_config():
    query = {
        "query": """
        query GetPod($id: ID!) {
            pod(id: $id) {
                id
                name
                gpuCount
                gpuTypeId
                status
            }
        }
        """,
        "variables": {"id": POD_ID}
    }

    r = requests.post(GRAPHQL_URL, headers=HEADERS, json=query)
    data = r.json().get("data", {}).get("pod", {})
    gpu_count = data.get("gpuCount", 0)
    status = data.get("status", "UNKNOWN")

    print(f"üîç Pod status: {status}, GPU count: {gpu_count}")
    if gpu_count == 0:
        raise Exception("‚ùå Ce pod n'a pas de GPU attach√©. Abandon du d√©marrage.")
    return status

# 2Ô∏è‚É£ Lance le pod s‚Äôil est stopp√©
def start_pod():
    print("üöÄ D√©marrage du pod via RunPod...")
    mutation = {
        "query": """
        mutation StartPod($podId: ID!) {
            podStart(input: { podId: $podId }) {
                id
                desiredStatus
            }
        }
        """,
        "variables": {"podId": POD_ID}
    }
    r = requests.post(GRAPHQL_URL, headers=HEADERS, json=mutation)
    result = r.json()
    if "errors" in result:
        raise Exception("‚ùå Erreur au d√©marrage du pod :", result["errors"])
    print("‚úÖ Pod en cours de d√©marrage...")

# 3Ô∏è‚É£ Attend que le pod soit RUNNING
def wait_for_pod_running(max_attempts=30):
    print("‚è≥ Attente que le pod passe en RUNNING...")
    for _ in range(max_attempts):
        query = {
            "query": """
            query GetPod($id: ID!) {
                pod(id: $id) {
                    status
                }
            }
            """,
            "variables": {"id": POD_ID}
        }
        r = requests.post(GRAPHQL_URL, headers=HEADERS, json=query)
        status = r.json().get("data", {}).get("pod", {}).get("status", "")
        print(f"   ‚û§ √âtat actuel : {status}")
        if status == "RUNNING":
            print("‚úÖ Pod est maintenant RUNNING.")
            return True
        time.sleep(10)
    raise Exception("‚ùå Le pod ne d√©marre pas apr√®s plusieurs tentatives.")

# 4Ô∏è‚É£ V√©rifie que l'API Mistral r√©pond
def wait_for_mistral_api(max_attempts=30):
    print(f"‚è≥ Attente de la disponibilit√© de l'API Mistral sur {MISTRAL_API}")
    for _ in range(max_attempts):
        try:
            r = requests.post(MISTRAL_API, json={"inputs": "Health check"}, timeout=10)
            if r.status_code == 200 and "outputs" in r.json():
                print("‚úÖ L'API Mistral est pr√™te √† recevoir des requ√™tes.")
                return True
        except Exception as e:
            print("   ‚û§ En attente de r√©ponse API...")
        time.sleep(10)
    raise Exception("‚ùå L'API Mistral ne r√©pond pas apr√®s plusieurs tentatives.")

# üîÅ Orchestration compl√®te
def main():
    try:
        status = check_gpu_config()
        if status == "STOPPED":
            start_pod()
        if status != "RUNNING":
            wait_for_pod_running()
        wait_for_mistral_api()
        print("üéØ Pod Mistral pr√™t pour enrich_sent_mistral.py")

    except Exception as e:
        print(str(e))

if __name__ == "__main__":
    main()
